{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ff3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import date\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9198b4",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f308fa3",
   "metadata": {},
   "source": [
    "The cell below shows the code used to train RF-Seward. Note that X (input features) and y (actual snow depths) datasets are not provided in this GitHub repository, but correspond to the DTP data described in the related manuscript (see readme file for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155d1015",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# RF-Seward training code \u001b[39;00m\n\u001b[1;32m      2\u001b[0m rf_best \u001b[38;5;241m=\u001b[39m RandomForestRegressor(bootstrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, max_features \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m, n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70\u001b[39m, min_samples_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m rf_best\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX\u001b[49m, y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# RF-Seward training code \n",
    "rf_best = RandomForestRegressor(bootstrap = True, max_depth = 10, max_features =2, max_samples = 0.8, n_estimators = 70, min_samples_leaf = 1, min_samples_split=15)\n",
    "rf_best.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5929a",
   "metadata": {},
   "source": [
    "# Input Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e779ed3",
   "metadata": {},
   "source": [
    "The code presented here was designed for pulling features from the NGEE-Arctic iButton datasets publically available on ESS-Dive (see readme file for more details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c57c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date from string to datetime object\n",
    "# DATA is an array of string dates, STRING is the string defining the date pattern\n",
    "# RETURNS an array of datetime objects \n",
    "def changedate(data, string):\n",
    "    return [datetime.strptime(i, string) for i in data]\n",
    "\n",
    "# Function to rename columns in a dataframe \n",
    "# DATA is the dataframe; OLDS are the current column names; NEWS are the desired column names\n",
    "# OLDs and NEWs can either be arrays of multipe names or single strings \n",
    "# RETURNS an updated dataframe with renamed columns \n",
    "def renamecols(data, olds, news):\n",
    "    if type(olds) == str: \n",
    "        return data.rename({olds: news}, axis = 1) \n",
    "    num = len(olds)\n",
    "    for i in np.arange(num):\n",
    "        data = data.rename({olds[i]: news[i]}, axis =1)\n",
    "    return data \n",
    "\n",
    "# Create an array of dates from dataframe RAWDATA by \n",
    "# pulling date from the existing COLNAME (default = 'DateTime') column.\n",
    "# RETURNS an array of dates. \n",
    "def add_date(rawdata, colname = 'DateTime'):\n",
    "    return [i.date() for i in rawdata[colname]]\n",
    "\n",
    "# Function to determine which time interval a data point belongs to. \n",
    "# TIME is a datetime and INTERVAL is the time interval that \n",
    "# RF-Seward features are calculated from. We use 4-hour intervals \n",
    "# because the iButton data we had was collected in 4-hour intervals.\n",
    "# This function was originally created to aggregate the training data from \n",
    "# 30-minute intervals to 4-hour intervals and is a little bit \n",
    "# unnecessary here. \n",
    "# RETURNS which time interval (or group) a datetime belongs to. \n",
    "def get_group(time, interval):\n",
    "    hours = np.arange(interval, 25, interval)\n",
    "    num = 1\n",
    "    hour = time.hour\n",
    "    for h in hours:\n",
    "        if hour < h: \n",
    "            return num \n",
    "        num = num + 1  \n",
    "        \n",
    "# RETURNS an array of 'groups' given a dataframe DATA, the desired\n",
    "# time interval INTERVAL, and the name of the DateTime column (COLNAME).\n",
    "def assign_group(data, interval, colname = 'DateTime'): \n",
    "    return [get_group(i, 4) for i in data[colname]]\n",
    "\n",
    "# RETURNS a cleaned DataFrame with all features used by RF-Seward given the RAWDATA. \n",
    "def iButton_clean(rawdata):\n",
    "    all_data = pd.DataFrame([])\n",
    "    rawdata = rawdata.copy()\n",
    "    rawdata = renamecols(rawdata, 'Temperature', 'GST')\n",
    "    try: \n",
    "        rawdata['DateTime'] = changedate(rawdata['Date_Time'], '%m/%d/%Y %H:%M:%S')\n",
    "    except:\n",
    "        try:\n",
    "            rawdata['DateTime'] = changedate(rawdata['Date_Time'], '%m/%d/%y %H:%M')\n",
    "        except:\n",
    "            rawdata['DateTime'] = changedate(rawdata['Date_Time'], '%Y-%m-%d %H:%M:%S')\n",
    "    rawdata = rawdata.drop('Date_Time', axis = 1)\n",
    "    rawdata['day'] = add_date(rawdata)\n",
    "    # The next 2 lines are little bit redundant because the data is already in 4-hour intervals \n",
    "    rawdata['hour_ind'] = assign_group(rawdata, 4)\n",
    "    rawdata = rawdata.groupby(['hour_ind', 'iButton', 'day']).mean()\n",
    "    rawdata = rawdata.reset_index()\n",
    "    rawdata = rawdata.drop('DateTime', axis = 1)\n",
    "    buttons = np.unique(rawdata['iButton'])\n",
    "    # The for loop below creates features for each iButton at a time and then combines \n",
    "    # everything into a single dataset \n",
    "    for  b in buttons:\n",
    "        data = rawdata.loc[rawdata['iButton']==b]\n",
    "        data = data.drop('iButton', axis = 1)\n",
    "        datam = create_features(data)\n",
    "        datam['iButton'] = b\n",
    "        all_data = pd.concat([all_data, datam])\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# RETURNS the mean, max, min, and standard deviation of DATA when grouped by COLS.\n",
    "def grouped_data(data, cols): \n",
    "    datamean = data.groupby(cols).mean()\n",
    "    datamax = data.groupby(cols).max()\n",
    "    datamin = data.groupby(cols).min()\n",
    "    datastd = data.groupby(cols).std()\n",
    "    datamean = datamean.reset_index()\n",
    "    datamax = datamax.reset_index()\n",
    "    datamin = datamin.reset_index() \n",
    "    datastd = datastd.reset_index()\n",
    "    return datamean, datamax, datamin, datastd \n",
    "\n",
    "# RETURNS a dataframe of features required by RF-SEWARD given DATA, \n",
    "# the window-size (WSIZE) for the features window-before, window-surrounding,\n",
    "# and 'window-after' (see readme), and the name of the 'day' column (COLS, default = 'day')\n",
    "def create_features(data, wsize = 30, cols = 'day'): \n",
    "    # Creating grouped datasets to get min, max, mean, stds \n",
    "    datamean, datamax, datamin, datastd = grouped_data(data, cols)\n",
    "    # Creating GST range feature \n",
    "    min_max_range = datamax['GST'] - datamin['GST']\n",
    "    # Initiating dataframe with features \n",
    "    datam = pd.DataFrame([])\n",
    "    datam['time'] = datamax.day\n",
    "    # Adding in GST_range and Max_GST as features \n",
    "    datam['GST_range'] = min_max_range \n",
    "    datam['Max_GST'] = datamax['GST']\n",
    "    datam['Min_GST'] = datamin['GST']\n",
    "    # Adding in window before feature\n",
    "    # Adding in nan data entries for days where no data was recorded \n",
    "    # because otherwise consecutive data entries would be aggregated \n",
    "    # over even if they weren't neighboring days.\n",
    "    dates = pd.date_range(datastd.day.values[0], datastd.day.values[-1])\n",
    "    datestable = pd.DataFrame([])\n",
    "    datestable['day'] = [i.date() for i in dates]\n",
    "    datastd = datastd.merge(datestable, how = 'outer', on = 'day')\n",
    "    window = [np.mean(np.array(datastd['GST'][i - wsize: i])) for i in np.arange(wsize, len(datastd))]\n",
    "    window = np.append(np.ones(wsize) * np.nan, window)\n",
    "    datastd['window'] = window\n",
    "    datam['GST_wk_prior'] = datastd['window']\n",
    "    # Adding GST_std and GST_av features, even though tese aren't used \n",
    "    # in the final model\n",
    "    datam['GST_std'] = datastd['GST']\n",
    "    datam['GST_av'] = datamean['GST']\n",
    "    #Adding in window after feature \n",
    "    window = [np.mean(np.array(datastd['GST'][i + 1: i + wsize + 1])) for i in np.arange(0, len(datastd) - wsize)]\n",
    "    window = np.append(window, np.ones(wsize) * np.nan)\n",
    "    datastd['window'] = window\n",
    "    datam['GST_wk_after'] = datastd['window']\n",
    "    #Adding in window surrounding feature \n",
    "    temp = int((wsize - 1)/2)\n",
    "    window = [np.mean(np.array(datastd['GST'][i - temp: i + temp + 1])) for i in np.arange(temp, len(datastd) - temp)]\n",
    "    window = np.append(window, np.ones(temp) * np.nan)\n",
    "    window = np.append(np.ones(temp) * np.nan, window)\n",
    "    datastd['window'] = window\n",
    "    datam['GST_wk_sur'] = datastd['window']\n",
    "    return datam \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6ca762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/jk9598l14tsb028s9yx9d10m00162w/T/ipykernel_10597/1148948345.py:2: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  iButton_data = pd.read_csv('../iButtons2022/2021_2022_TL27_iButton_snow_temperatures.csv')\n"
     ]
    }
   ],
   "source": [
    "# Reading in iButton data \n",
    "iButton_data = pd.read_csv('../iButtons2022/2021_2022_TL27_iButton_snow_temperatures.csv')\n",
    "# Creating iButton features \n",
    "iButton_data = iButton_data.loc[:, ['iButton', 'Date_Time', 'Temperature']]\n",
    "iButton_features = iButton_clean(iButton_data)\n",
    "# List of features used in the final model\n",
    "cols = [ 'GST_wk_after', 'GST_range', 'GST_wk_prior', 'GST_wk_sur', 'Max_GST']\n",
    "# Dropping nans because the random forest model can not handle nans \n",
    "iButton_features = iButton_features.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b1120",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67f26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in joblib random forest\n",
    "rf_seward = joblib.load('rf_seward.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72a8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the features calculated in the previous section\n",
    "snow_pred = rf_seward.predict(iButton_features.loc[:, cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
